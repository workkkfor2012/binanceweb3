// packages/backend/src/kline_handler.rs

use crate::{
    client_pool::ClientPool,
    types::{HistoricalDataWrapper, KlineHistoryResponse, KlineSubscribePayload, KlineTick},
    ServerState,
};
use anyhow::{anyhow, Context, Result};
use chrono::{DateTime, Duration, Utc};
use reqwest::Client;
use serde_json::Value;
use socketioxide::extract::{Data, SocketRef};
use sqlx::{
    sqlite::{SqlitePool, SqliteRow},
    Row,
};
use std::time::Instant;
use tokio_retry::{strategy::ExponentialBackoff, Retry};
use tracing::{error, info, warn};

const API_URL_TEMPLATE: &str = "https://dquery.sintral.io/u-kline/v1/k-line/candles?address={address}&interval={interval}&limit={limit}&platform={platform}";
const API_MAX_LIMIT: i64 = 500;
const DB_MAX_RECORDS: i64 = 1000;
const DB_PRUNE_TO_COUNT: i64 = 500;
const FETCH_RETRY_COUNT: usize = 3;

pub async fn init_db(pool: &SqlitePool) -> Result<()> {
    sqlx::query(
        "CREATE TABLE IF NOT EXISTS klines (
            primary_key TEXT NOT NULL,
            time INTEGER NOT NULL,
            open REAL NOT NULL,
            high REAL NOT NULL,
            low REAL NOT NULL,
            close REAL NOT NULL,
            volume REAL NOT NULL,
            PRIMARY KEY (primary_key, time)
        )",
    )
    .execute(pool)
    .await?;
    info!("üóÉÔ∏è 'klines' table is ready.");
    Ok(())
}

pub async fn handle_kline_request(
    s: SocketRef,
    Data(payload): Data<KlineSubscribePayload>,
    state: ServerState,
) {
    let start_total = Instant::now();
    let primary_key = get_primary_key(&payload);

    // --- Ê≠•È™§ 1: Á´ãÂç≥Êü•ËØ¢Êï∞ÊçÆÂ∫ìÂπ∂ËøîÂõû (ÂêåÊ≠•Ë∑ØÂæÑ) ---
    let db_start = Instant::now();
    let initial_data = match get_klines_from_db(&state.db_pool, &primary_key).await {
        Ok(data) => {
            let db_duration = db_start.elapsed();
            if !data.is_empty() {
                let last_time = data.last().unwrap().time;
                info!(
                    "üíæ [DB HIT] {} records for {}. Last Candle: {} (Took {:?})",
                    data.len(),
                    primary_key,
                    last_time,
                    db_duration
                );
            } else {
                info!(
                    "üíæ [DB MISS] No records found for {} (Took {:?})",
                    primary_key,
                    db_duration
                );
            }
            data
        }
        Err(e) => {
            error!("‚ùå [DB ERROR] for {}: {}", primary_key, e);
            vec![]
        }
    };

    // ÂèëÈÄÅÂàùÂßãÊï∞ÊçÆ
    let initial_response = KlineHistoryResponse {
        address: payload.address.clone(),
        chain: payload.chain.clone(),
        interval: payload.interval.clone(),
        data: initial_data,
    };

    if let Err(e) = s.emit("historical_kline_initial", &initial_response) {
        error!("‚ùå [EMIT ERROR] initial for {}: {}", primary_key, e);
    }

    info!(
        "üöÄ [PERF STEP 1] {} -> DB Data Sent to Client in {:?}",
        primary_key,
        start_total.elapsed()
    );

    // --- Ê≠•È™§ 2: ÂêéÂè∞Ë°•ÂÖ®Áº∫Â§±Êï∞ÊçÆ (ÂºÇÊ≠•Ë∑ØÂæÑ) ---
    tokio::spawn(async move {
        let api_process_start = Instant::now();

        match complete_kline_data(&payload, &state, &primary_key, &s).await {
            Ok(Some(count)) => {
                let api_duration = api_process_start.elapsed();
                let total_duration = start_total.elapsed();
                info!(
                    "üì° [PERF STEP 2] {} -> Fetched & Sent {} NEW/UPDATED candles. (API: {:?}, Total E2E: {:?})",
                    primary_key,
                    count,
                    api_duration,
                    total_duration
                );
            }
            Ok(None) => {
                // ÁêÜËÆ∫‰∏äÁé∞Âú®ÂæàÂ∞ë‰ºöËøõÂÖ•ËøôÈáåÔºåÈô§Èùû limit <= 0
            }
            Err(e) => {
                error!("‚ùå [FETCH FAILED] for {}: {:?}", primary_key, e);
                let err_payload = serde_json::json!({ "key": primary_key, "error": e.to_string() });
                s.emit("kline_fetch_error", &err_payload).ok();
            }
        }
    });
}

async fn complete_kline_data(
    payload: &KlineSubscribePayload,
    state: &ServerState,
    primary_key: &str,
    s: &SocketRef,
) -> Result<Option<usize>> {
    let last_kline = get_last_kline_from_db(&state.db_pool, primary_key).await?;
    let interval_ms = interval_to_ms(&payload.interval);
    let now = Utc::now();

    let mut limit = match last_kline {
        Some(kline) => {
            let time_diff_ms = now.timestamp_millis() - kline.time.timestamp_millis();
            // Âç≥‰ΩøÊó∂Èó¥Â∑ÆÂæàÂ∞èÔºåÂè™Ë¶Å interval_ms Â§ß‰∫é 0Ôºålimit Ëá≥Â∞ë‰∏∫ 1
            // Ëøô‰øùËØÅ‰∫ÜÊàë‰ª¨ÊÄªÊòØ‰ºöÂéªÊãâÂèñÊúÄÊñ∞ÁöÑ‰∏ÄÊ†π K Á∫øÊù•Êõ¥Êñ∞ÂÆÉÁöÑÁä∂ÊÄÅ
            let missing_count = (time_diff_ms / interval_ms).max(1);
            
            if missing_count > 1 {
                info!(
                    "üïµÔ∏è [CHECK {}] Gap detected. Last: {}, Now: {}, Need ~{} candles.", 
                    primary_key, kline.time, now, missing_count
                );
            } else {
                info!(
                    "üîÑ [CHECK {}] Database has latest timestamp, but refreshing active candle (Limit=1).", 
                    primary_key
                );
            }
            
            missing_count
        }
        None => {
            info!("üïµÔ∏è [CHECK {}] Empty DB. Triggering full fetch (500).", primary_key);
            API_MAX_LIMIT
        },
    };

    if limit <= 0 {
        return Ok(None);
    }

    if limit > API_MAX_LIMIT {
        warn!(
            "‚ö†Ô∏è [STALE] {} missing {} candles (Too many). Resetting to {}.",
            primary_key, limit, API_MAX_LIMIT
        );
        clear_klines_from_db(&state.db_pool, primary_key).await?;
        limit = API_MAX_LIMIT;
    }

    // ÊâßË°åÁΩëÁªúËØ∑Ê±Ç
    let new_klines = fetch_historical_data_with_pool(&state.client_pool, payload, limit).await?;

    if new_klines.is_empty() {
        warn!("‚ö†Ô∏è [API EMPTY] Returned 0 candles for {}", primary_key);
        return Ok(Some(0));
    }

    // ‚ú®‚ú®‚ú® Ê†∏ÂøÉÈÄªËæëÔºöÊ≥®ÂÖ•Êï∞ÊçÆÂà∞ RoomÔºåËÆ© WebSocket ÁöÑ tx Êï∞ÊçÆÁ´ãÂç≥ÂèØÁî® ‚ú®‚ú®‚ú®
    // 1. ËÆ°ÁÆó Room Name (ÈúÄË¶ÅÂíå socket_handlers.rs ÈÄªËæë‰∏ÄËá¥)
    let chain_lower = payload.chain.to_lowercase();
    let pool_id = match chain_lower.as_str() {
        "bsc" => 14,
        "sol" | "solana" => 16,
        "base" => 199,
        _ => 0, // ËøôÁßçÊÉÖÂÜµ‰∏ãÈÄöÂ∏∏‰∏ç‰ºöËµ∞Âà∞ËøôÈáåÔºåÊàñËÄÖÂú® socket handler Â∞±Êã¶Êà™‰∫Ü
    };
    
    if pool_id != 0 {
        let room_name = format!("kl@{}@{}@{}", pool_id, payload.address, payload.interval);
        
        // 2. Êü•ÊâæÊàøÈó¥Âπ∂Ê≥®ÂÖ•
        if let Some(room) = state.app_state.get(&room_name) {
             if let Some(last_candle) = new_klines.last() {
                 let mut lock = room.current_kline.lock().await;
                 // Âè™ÊúâÂΩìÂÆÉÊòØ None Êó∂ÊâçÊ≥®ÂÖ•ÔºàÈÅøÂÖçË¶ÜÁõñ‰∫ÜÂèØËÉΩÂ∑≤ÁªèÂà∞ËææÁöÑ WS kl Êï∞ÊçÆÔºâ
                 // ÊàñËÄÖÔºöÂº∫Âà∂Ê≥®ÂÖ•‰πüÊ≤°ÈóÆÈ¢òÔºåÂõ†‰∏∫ HTTP ÁöÑÊï∞ÊçÆÊòØ "snapshot"ÔºåÈÄöÂ∏∏ÂæàÊñ∞
                 // ‰∏∫‰∫Ü‰øùÈô©ÔºåÊàë‰ª¨Âè™Âú® None Êó∂Ê≥®ÂÖ•ÔºåÂõ†‰∏∫Â¶ÇÊûúÂÆÉ‰∏çÊòØ NoneÔºåËØ¥Êòé WS Â∑≤ÁªèÊ≠£Â∏∏Â∑•‰Ωú‰∫Ü
                 if lock.is_none() {
                     *lock = Some(last_candle.clone());
                     info!("üíâ [INJECT] Successfully injected HTTP candle into WebSocket state for {}", room_name);
                 }
             }
        }
    }

    // Á´ãÂç≥ÂèëÈÄÅÁªôÂâçÁ´Ø
    let emit_start = Instant::now();
    let completed_response = KlineHistoryResponse {
        address: payload.address.clone(),
        chain: payload.chain.clone(),
        interval: payload.interval.clone(),
        data: new_klines.clone(),
    };

    if let Err(e) = s.emit("historical_kline_completed", &completed_response) {
        error!("‚ùå [EMIT ERROR] completed for {}: {}", primary_key, e);
    } else {
        // info!("üöÄ [PERF EMIT] Data sent to client in {:?} (Before DB write)", emit_start.elapsed());
    }

    // ÂºÇÊ≠•Â≠òÂ∫ì
    save_klines_to_db(&state.db_pool, primary_key, &new_klines).await?;
    prune_old_klines_from_db(&state.db_pool, primary_key).await?;

    Ok(Some(new_klines.len()))
}

async fn fetch_historical_data_with_pool(
    pool: &ClientPool,
    payload: &KlineSubscribePayload,
    limit: i64,
) -> Result<Vec<KlineTick>> {
    let formatted_interval = format_interval_for_api(&payload.interval);
    let url = API_URL_TEMPLATE
        .replace("{address}", &payload.address)
        .replace("{platform}", &payload.chain)
        .replace("{interval}", &formatted_interval)
        .replace("{limit}", &limit.to_string());

    let interval_label = payload.interval.clone();

    for attempt in 1..=3 {
        let (client_idx, client) = pool.get_client().await;
        
        let http_start = Instant::now();

        match client.get(&url).send().await {
            Ok(response) => {
                info!("‚ö° [PERF HTTP] Request took {:?}", http_start.elapsed());
                
                if !response.status().is_success() {
                     warn!("‚ùå [API FAIL] Status: {}. Recycling node #{}...", response.status(), client_idx);
                     pool.recycle_client(client_idx).await;
                     continue;
                }
                
                let text_response = response.text().await?;
                match serde_json::from_str::<HistoricalDataWrapper>(&text_response) {
                    Ok(wrapper) => {
                        match parse_api_data(&wrapper.data, &interval_label) {
                            Ok(data) => {
                                return Ok(data);
                            },
                            Err(e) => {
                                return Err(anyhow!("Data parse error: {}", e));
                            }
                        }
                    }
                    Err(e) => {
                        warn!("‚ùå [JSON PARSE FAIL] Error: {}. Recycling node #{}", e, client_idx);
                        pool.recycle_client(client_idx).await;
                    }
                }
            },
            Err(e) => {
                warn!("‚ùå [NET FAIL] Error: {}. Recycling node #{} and retrying...", e, client_idx);
                pool.recycle_client(client_idx).await;
            }
        }
    }

    Err(anyhow!("All 3 attempts failed."))
}

async fn get_klines_from_db(pool: &SqlitePool, primary_key: &str) -> Result<Vec<KlineTick>> {
    sqlx::query_as::<_, KlineTick>(
        "SELECT time, open, high, low, close, volume FROM klines WHERE primary_key = ? ORDER BY time ASC",
    )
    .bind(primary_key)
    .fetch_all(pool)
    .await
    .context("Failed to fetch all klines from DB")
}

async fn get_last_kline_from_db(pool: &SqlitePool, primary_key: &str) -> Result<Option<KlineTick>> {
    sqlx::query_as(
        "SELECT time, open, high, low, close, volume FROM klines WHERE primary_key = ? ORDER BY time DESC LIMIT 1",
    )
    .bind(primary_key)
    .fetch_optional(pool)
    .await
    .context("Failed to fetch last kline from DB")
}

async fn save_klines_to_db(
    pool: &SqlitePool,
    primary_key: &str,
    klines: &[KlineTick],
) -> Result<()> {
    if klines.is_empty() {
        return Ok(());
    }
    let mut tx = pool.begin().await?;
    for kline in klines {
        sqlx::query(
            "INSERT OR REPLACE INTO klines (primary_key, time, open, high, low, close, volume) VALUES (?, ?, ?, ?, ?, ?, ?)"
        )
        .bind(primary_key)
        .bind(kline.time.timestamp())
        .bind(kline.open)
        .bind(kline.high)
        .bind(kline.low)
        .bind(kline.close)
        .bind(kline.volume)
        .execute(&mut *tx)
        .await?;
    }
    tx.commit()
        .await
        .context("Failed to commit transaction for saving klines")
}

async fn clear_klines_from_db(pool: &SqlitePool, primary_key: &str) -> Result<()> {
    sqlx::query("DELETE FROM klines WHERE primary_key = ?")
        .bind(primary_key)
        .execute(pool)
        .await?;
    Ok(())
}

async fn prune_old_klines_from_db(pool: &SqlitePool, primary_key: &str) -> Result<()> {
    let count: i64 = sqlx::query("SELECT COUNT(*) FROM klines WHERE primary_key = ?")
        .bind(primary_key)
        .fetch_one(pool)
        .await?
        .get(0);

    if count > DB_MAX_RECORDS {
        let limit = count - DB_PRUNE_TO_COUNT;
        sqlx::query(
            "DELETE FROM klines WHERE rowid IN (
                SELECT rowid FROM klines WHERE primary_key = ? ORDER BY time ASC LIMIT ?
            )",
        )
        .bind(primary_key)
        .bind(limit)
        .execute(pool)
        .await?;
    }
    Ok(())
}

fn get_primary_key(payload: &KlineSubscribePayload) -> String {
    format!(
        "{}@{}@{}",
        payload.address.to_lowercase(),
        payload.chain.to_lowercase(),
        payload.interval
    )
}

fn interval_to_ms(interval: &str) -> i64 {
    let value_str: String = interval.chars().take_while(|c| c.is_ascii_digit()).collect();
    let unit: String = interval.chars().skip_while(|c| c.is_ascii_digit()).collect();
    let value = value_str.parse::<i64>().unwrap_or(0);
    match unit.as_str() {
        "m" => Duration::minutes(value).num_milliseconds(),
        "h" => Duration::hours(value).num_milliseconds(),
        "d" => Duration::days(value).num_milliseconds(),
        _ => 0,
    }
}

fn format_interval_for_api(interval: &str) -> String {
    if let Some(val) = interval.strip_suffix('m') {
        format!("{}min", val)
    } else {
        interval.to_string()
    }
}

fn parse_api_data(data: &[Vec<Value>], interval_label: &str) -> Result<Vec<KlineTick>> {
    let extract_f64 = |v: &Value, name: &str| -> Result<f64> {
        if let Some(f) = v.as_f64() {
            return Ok(f);
        }
        if let Some(s) = v.as_str() {
            return s.parse::<f64>().map_err(|_| {
                anyhow!("Invalid float string for {}: {}", name, s)
            });
        }
        if let Some(i) = v.as_i64() {
            return Ok(i as f64);
        }
        Ok(0.0)
    };

    data.iter()
        .map(|d| -> Result<KlineTick> {
            let timestamp_ms = d.get(5).and_then(|v| v.as_i64()).unwrap_or(0);
            Ok(KlineTick {
                time: DateTime::from_timestamp(timestamp_ms / 1000, 0)
                    .context("Invalid timestamp")?
                    .with_timezone(&Utc),
                open: extract_f64(d.get(0).unwrap_or(&Value::Null), "open")?,
                high: extract_f64(d.get(1).unwrap_or(&Value::Null), "high")?,
                low: extract_f64(d.get(2).unwrap_or(&Value::Null), "low")?,
                close: extract_f64(d.get(3).unwrap_or(&Value::Null), "close")?,
                volume: extract_f64(d.get(4).unwrap_or(&Value::Null), "volume")?,
            })
        })
        .collect()
}

impl sqlx::FromRow<'_, SqliteRow> for KlineTick {
    fn from_row(row: &SqliteRow) -> sqlx::Result<Self> {
        let timestamp_secs: i64 = row.try_get("time")?;
        Ok(KlineTick {
            time: DateTime::from_timestamp(timestamp_secs, 0)
                .unwrap_or_default()
                .with_timezone(&Utc),
            open: row.try_get("open")?,
            high: row.try_get("high")?,
            low: row.try_get("low")?,
            close: row.try_get("close")?,
            volume: row.try_get("volume")?,
        })
    }
}